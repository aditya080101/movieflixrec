{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "da447453-96e3-48fe-93cd-b9195433add6",
    "_uuid": "b63091dc0b9d04f19ab8861754a83b79c1789e96"
   },
   "source": [
    "# Movies Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5ec09319-a139-488b-b9fa-51780fd771dc",
    "_uuid": "93799938d163a5c4d6097e04fc566c04a1237718"
   },
   "source": [
    "![](http://labs.criteo.com/wp-content/uploads/2017/08/CustomersWhoBought3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "351091d0-4223-4510-b737-3d109883c4bf",
    "_uuid": "c9e02ccf7a6f04280a8a949fe82cc3c12f8a769f"
   },
   "source": [
    "I will be  implementing a few recommendation algorithms (content based, popularity based) and try to build  final recommendation system.\n",
    "\n",
    "With us, we have two MovieLens datasets.\n",
    "* **The Full Dataset:** Consists of 26,000,000 ratings and 750,000 tag applications applied to 45,000 movies by 270,000 users. Includes tag genome data with 12 million relevance scores across 1,100 tags.\n",
    "* **The Small Dataset:** Comprises of 100,000 ratings and 1,300 tag applications applied to 9,000 movies by 700 users.\n",
    "\n",
    "Firstly I will build a Simple Recommender using movies from the *Full Dataset* \n",
    "Then I will implement The Content Based recommender systems will make use of the small dataset (due to the computing power I possess being very limited)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "78fea705-f9ad-4a81-aafd-8b7b624110d1",
    "_uuid": "1c291fe3725c706e0003f01f0102abb9709f25fc"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f130bae8-1bb0-415d-9a39-557fe180b490",
    "_uuid": "49131e65f312719487848f6ef42488041a44028e"
   },
   "source": [
    "## Simple Recommender\n",
    "\n",
    "The Simple Recommender offers generalized recommendations to every user based on movie popularity and (sometimes) genre. The basic idea behind this recommender is that movies that are more popular and more critically acclaimed will have a higher probability of being liked by the average audience. This model does not give personalized recommendations based on the user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0356d2a0-d8b2-4234-af78-bd51eaa3a390",
    "_uuid": "e0d62612bc9b9e9561afdc48fd1e75a9b0c82337"
   },
   "outputs": [],
   "source": [
    "df = pd. read_csv('movies_metadata.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f933a861-409a-4df7-98f1-7960a2a3874b",
    "_uuid": "d4df4c2158595611f2ea7ad4b16f71900e529ea8"
   },
   "outputs": [],
   "source": [
    "df['genres'] = df['genres'].fillna('[]').apply(literal_eval).apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "23cf39ba-ef09-4972-9d1f-ed91cb2ef134",
    "_uuid": "9571875d383f237f126febe9c76f966e2869fdc3"
   },
   "source": [
    "I will use IMDB's *weighted rating* formula to construct my chart. Mathematically, it is represented as follows:\n",
    "\n",
    "Weighted Rating (WR) = $(\\frac{v}{v + m} . R) + (\\frac{m}{v + m} . C)$\n",
    "\n",
    "\n",
    "where,\n",
    "* *v* is the number of votes for the movie\n",
    "* *m* is the minimum votes required to be listed in the chart\n",
    "* *R* is the average rating of the movie\n",
    "* *C* is the mean vote across the whole report\n",
    "\n",
    "The next step is to determine an appropriate value for *m*, the minimum votes required to be listed in the chart. for a movie to feature in the charts, it must have more votes than at least 95% of the movies in the list( i.e we will use 95 percentile system to get the minimum votes required to be listed in chart)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "de5d2a9a-9d67-4309-9256-844756318bd0",
    "_uuid": "1e732487caba09d9543f3da49cbe7ff5092e2675"
   },
   "outputs": [],
   "source": [
    "vote_counts = df[df['vote_count'].notnull()]['vote_count'].astype('int')\n",
    "vote_averages = df[df['vote_average'].notnull()]['vote_average'].astype('int')\n",
    "C = vote_averages.mean()\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f2a3dff7-6430-471b-bd83-589779ab52b0",
    "_uuid": "23c2e113380f1bad9205ab2d0f8c372b0c246e79"
   },
   "outputs": [],
   "source": [
    "m = vote_counts.quantile(0.95)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "93f480df-6e7b-427c-bbc0-906fd41640b0",
    "_uuid": "dbb8261dedb84e4a8ea8bed843c9de3ad9f3859d"
   },
   "outputs": [],
   "source": [
    "df['year'] = pd.to_datetime(df['release_date'], errors='coerce').apply(lambda x: str(x).split('-')[0] if x != np.nan else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e7e91af4-7ff5-4553-bfbb-b9339096397e",
    "_uuid": "dcb30bee69ef1a6ead2c745565e5e7bfd5314d7a"
   },
   "outputs": [],
   "source": [
    "qualified_movies = df[(df['vote_count'] >= m) & (df['vote_count'].notnull()) & (df['vote_average'].notnull())][['title', 'year', 'vote_count', 'vote_average', 'popularity', 'genres']]\n",
    "qualified_movies['vote_count'] = qualified_movies['vote_count'].astype('int')\n",
    "qualified_movies['vote_average'] = qualified_movies['vote_average'].astype('int')\n",
    "qualified_movies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "46efcb66-53a0-4f6a-b0df-92ba7b623143",
    "_uuid": "4c114ab330fc78c91953166d515a8e963ebc3238"
   },
   "source": [
    "the minimum votes required to be listed in the chart is 434.0.\n",
    "\n",
    "the mean vote across the whole report is 5.244896612406511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "db959c40-7618-4755-a05a-5347f9460929",
    "_uuid": "6414e1aa7ed8cb4184ec451f02a18cd187e5345e"
   },
   "outputs": [],
   "source": [
    "def weighted_rating(x):\n",
    "    v = x['vote_count']\n",
    "    R = x['vote_average']\n",
    "    return (v/(v+m) * R) + (m/(m+v) * C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0f5e4384-51be-41df-a023-12a13e77d66c",
    "_uuid": "78ec5052b0e89ae51a834aa3a305cf55b6849f42"
   },
   "outputs": [],
   "source": [
    "qualified_movies['weighted_rating'] = qualified_movies.apply(weighted_rating, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ccbd8eca-cbfe-4843-9885-de11976f117c",
    "_uuid": "ed0ac7c8483f904d4f5ec0d554096d4782fa8bcf"
   },
   "outputs": [],
   "source": [
    "qualified_movies = qualified_movies.sort_values('weighted_rating', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "36a1b9ac-aff3-4d80-9e19-83a45f282062",
    "_uuid": "75eb9e1de05386d229746785a25c6a5c6ee4b61a"
   },
   "source": [
    "# Top Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0bca5b03-0835-4902-aaa1-beceb9d9d47f",
    "_uuid": "f7f6821b7e9aff099b81fcc425fd20109894b351"
   },
   "outputs": [],
   "source": [
    "qualified_movies.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Movies Based on Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c6be871d-62d4-4ec4-abe4-6ca1b1c01fa0",
    "_uuid": "b59a35544efcd50e89e4bb1ea14bbfe32fc9bcd3"
   },
   "outputs": [],
   "source": [
    "new_df = df.apply(lambda x: pd.Series(x['genres']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "new_df.name = 'genre'\n",
    "gen_df = df.drop('genres', axis=1).join(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "759652cb-5b16-4951-995c-6a3bdbae0e4e",
    "_uuid": "1fdfea9cd4b046b11ff8f2ac4f2bea74fccb8a8b"
   },
   "outputs": [],
   "source": [
    "def genrebasedrec(genre, percentile=0.95):\n",
    "    df = gen_df[gen_df['genre'] == genre]\n",
    "    vote_counts = df[df['vote_count'].notnull()]['vote_count'].astype('int')\n",
    "    vote_averages = df[df['vote_average'].notnull()]['vote_average'].astype('int')\n",
    "    C = vote_averages.mean()\n",
    "    m = vote_counts.quantile(percentile)\n",
    "    \n",
    "    qualified = df[(df['vote_count'] >= m) & (df['vote_count'].notnull()) & (df['vote_average'].notnull())][['title', 'year', 'vote_count', 'vote_average', 'popularity']]\n",
    "    qualified['vote_count'] = qualified['vote_count'].astype('int')\n",
    "    qualified['vote_average'] = qualified['vote_average'].astype('int')\n",
    "    \n",
    "    qualified['weighted_rating'] = qualified.apply(lambda x: (x['vote_count']/(x['vote_count']+m) * x['vote_average']) + (m/(m+x['vote_count']) * C), axis=1)\n",
    "    qualified = qualified.sort_values('weighted_rating', ascending=False).head(250)\n",
    "    \n",
    "    return qualified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "55f22de0-0df9-405a-9197-df5a8c0e8466",
    "_uuid": "a76ce0f8a8f614aa6f23cb9a6e0fd6af6d048642"
   },
   "source": [
    "# Top Romance Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "af61da24-494b-48ac-b7b7-64ec0eaedaf8",
    "_uuid": "bf2816495a16de1bb84dc826fd33eee7e663f45d"
   },
   "outputs": [],
   "source": [
    "genrebasedrec('Romance').head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Action Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genrebasedrec('Action').head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b6e1eb8b-6109-40ff-ab8a-37bd047c03ac",
    "_uuid": "0b0f95bdf966d06c2d7053535d46183b03a75cc1"
   },
   "source": [
    "# Content Based Recommender\n",
    "\n",
    "Why we need the content based recommender?why simple recommendor system was not enough?\n",
    " \n",
    "Simple Recommender System  gives the same recommendation to everyone, regardless of the user's personal taste. If a person who loves romantic movies (and hates action) were to look at our Top 15 Chart, s/he wouldn't probably like most of the movies. If someone look at our charts by genre, he/she wouldn't still be getting the best recommendations.\n",
    "\n",
    "To personalise our recommendations more, we will do **Content Based Filtering.** and we will try to improve it further so that we have better recommendations.\n",
    "\n",
    "We will use the small dataset provided "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bd5f4440-f90d-46a4-8640-204541d99d40",
    "_uuid": "dc237e14c8346bdd51624d21b6b082399afd3062"
   },
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('links_small.csv')\n",
    "new_df = new_df[new_df['tmdbId'].notnull()]['tmdbId'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting the rows with bad format data\n",
    "df = df.drop([19730, 29503, 35587])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f68cb861-7c30-4b3d-b655-520379e61d70",
    "_uuid": "87eb84540a3c22a3f7bf54edeee5b491ef571416"
   },
   "outputs": [],
   "source": [
    "#Check Notebook for how and why I got these indices.\n",
    "df['id'] = df['id'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0b968a6a-6b0d-4df6-9e28-91c06e6c36c2",
    "_uuid": "3f2a7f55a030beeb06b713f854e4ca6a69b5ca13"
   },
   "outputs": [],
   "source": [
    "small_data = df[df['id'].isin(new_df)]\n",
    "small_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1e73645a-0b0b-441f-93b4-ce92069e1852",
    "_uuid": "c41800b7a9d8b8d48ba1c22b8430929f54e9884e"
   },
   "source": [
    "### Movie Description Based Recommender\n",
    "\n",
    "Let us first try to build a recommender using movie descriptions and taglines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c880adf9-051b-40cd-8e95-cd8c4acabb17",
    "_uuid": "453bdc941ba5a1e86e17b0f106dc44040c0defdf"
   },
   "outputs": [],
   "source": [
    "small_data['tagline'] = small_data['tagline'].fillna('')\n",
    "small_data['description'] = small_data['overview'] + small_data['tagline']\n",
    "small_data['description'] = small_data['description'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6b385623-a978-43c4-b66a-813d5e9c6790",
    "_uuid": "f9d99726d9f2667fa6fc15ce5c5e31d36a970828"
   },
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(small_data['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5e18427c-2ef8-4a98-84e2-323a4af72ade",
    "_uuid": "6c21cc05d3c13ea637028f2e5836c719986e47c7"
   },
   "outputs": [],
   "source": [
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7d4db389-9f30-46e9-b8af-69fe9b40ada5",
    "_uuid": "1a98e05af67de3475999e1891d965ce9f73ce316"
   },
   "source": [
    "#### Cosine Similarity\n",
    "\n",
    "We will be using the Cosine Similarity to calculate a numeric quantity that denotes the similarity between two movies. Mathematically, it is defined as follows:\n",
    "\n",
    "$cosine(x,y) = \\frac{x. y^\\intercal}{||x||.||y||} $\n",
    "\n",
    "Since we have used the TF-IDF Vectorizer, calculating the Dot Product will directly give us the Cosine Similarity Score. Therefore, we will use sklearn's **linear_kernel** instead of cosine_similarities since it is much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8b27b34f-a585-42bf-b35f-1de4e9181fce",
    "_uuid": "e324c0e951287359f7810a3da85631ebc7725c53"
   },
   "outputs": [],
   "source": [
    "similarity = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "148a994f-3e7f-4350-9ea3-41eb95f106e8",
    "_uuid": "ebb6823a9dce997d965dc89049a06512cbfb17af"
   },
   "outputs": [],
   "source": [
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "446d22fd-e7c1-42a6-851b-593f60175ce0",
    "_uuid": "ff016d61895e99fe7b0495c51b86917bdbe2712d"
   },
   "outputs": [],
   "source": [
    "small_data = small_data.reset_index()\n",
    "titles = small_data['title']\n",
    "indices = pd.Series(small_data.index, index=small_data['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d7352ae7-fbc3-4459-b257-76a44000ce6a",
    "_uuid": "62f49212a8b935ef63a3643e1bb6f629521f05b7"
   },
   "outputs": [],
   "source": [
    "def get_recommendations(title):\n",
    "    idx = indices[title]\n",
    "    similarity_scores = list(enumerate(similarity[idx]))\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "    similarity_scores = similarity_scores[1:31]\n",
    "    movie_indices = [i[0] for i in similarity_scores]\n",
    "    return titles.iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "73bb1266-5797-47ce-b61f-fa9e0d7ce077",
    "_uuid": "46f418fd12b35e86a7a2026ef1975be822cadde3"
   },
   "outputs": [],
   "source": [
    "get_recommendations('The Family').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d074112e-79ea-4188-a1e0-addd9bed3c91",
    "_uuid": "f92e310b0225b4a1b8b46e8a87fe2f2b82c158ed"
   },
   "outputs": [],
   "source": [
    "get_recommendations('Batman Forever').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a9fd334d-e890-4125-9d48-b79babd194d2",
    "_uuid": "f38218c5d4f07d6d9439adbab468c51430157103"
   },
   "source": [
    "We see that for **Batman Forever**, this recommendation system is able to identify it as a Batman film and subsequently recommend other Batman films as its top recommendations. But unfortunately, that is all this system can do at the moment. This is not of much use to most people as it doesn't take into considerations very important features such as cast, crew, director and genre, which determine the rating and the popularity of a movie.\n",
    "\n",
    "Someone who liked **The Dark Knight** probably likes it more because of Nolan and would hate **Batman Forever** and every other substandard movie in the Batman Franchise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3a0dd8ba-a580-4c12-95eb-ca04e2191b35",
    "_uuid": "4089c7bcdf984e596e80d2fc6c2a74fe8c05a41f"
   },
   "source": [
    "### Metadata Based Recommender\n",
    "\n",
    "we are going to use much more suggestive metadata than **Overview** and **Tagline**. metadata_based recommender will take **genre**, **keywords**, **cast** and **crew** into consideration.\n",
    "\n",
    "To build metadata based content recommender, we will need to merge our current dataset with the crew and the keyword datasets. Let us prepare this data as our first step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "85d2d5e0-165a-4ad5-860d-be1d1aa20c59",
    "_uuid": "aa399813ff512b0d7671e9bfcebf7f41ee139275"
   },
   "outputs": [],
   "source": [
    "credits = pd.read_csv('credits.csv')\n",
    "keywords = pd.read_csv('keywords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5dc74705-17ee-41b8-932b-dc612c9426c5",
    "_uuid": "e82eb38c3ae53d500ad335943b4bd30a19f22d1a"
   },
   "outputs": [],
   "source": [
    "keywords['id'] = keywords['id'].astype('int')\n",
    "credits['id'] = credits['id'].astype('int')\n",
    "df['id'] = df['id'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a120fca0-7236-4b97-97f8-970363ed02ed",
    "_uuid": "2f9fc363f77649b3ee41132e0b45f366726a25cb"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "39fbbbcd-a0d9-4ad3-9187-e6e2bdb4358e",
    "_uuid": "4b1ebc18f31eb017c6f4f173ab270807c73c002a"
   },
   "outputs": [],
   "source": [
    "df = df.merge(credits, on='id')\n",
    "df = df.merge(keywords, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ecdbd741-d8b1-4083-ba26-6c347915f16d",
    "_uuid": "a017f13dce80c88ce2f9fc0d63c374c93e827baa"
   },
   "outputs": [],
   "source": [
    "small_data1 = df[df['id'].isin(new_df)]\n",
    "small_data1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5932e964-9f33-4cac-b90c-d6a116c8c463",
    "_uuid": "8e2c893fd842164c99b1be3f84f11fac3adab387"
   },
   "source": [
    "We now have our cast, crew, genres and credits, all in one dataframe.\n",
    "\n",
    "1. **Crew:** From the crew, we will only pick the director as our feature since the others don't contribute that much to the *feel* of the movie.\n",
    "2. **Cast:** Choosing Cast is a little more tricky. Lesser known actors and minor roles do not really affect people's opinion of a movie. Therefore, we must only select the major characters and their respective actors. Arbitrarily we will choose the top 3 actors that appear in the credits list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6c221b12-c5fd-4eb6-b61a-b7d3f395d2ab",
    "_uuid": "7ff7d25e2c175f2d71e02cf408ed113e10a148f1"
   },
   "outputs": [],
   "source": [
    "small_data1['cast'] = small_data1['cast'].apply(literal_eval)\n",
    "small_data1['crew'] = small_data1['crew'].apply(literal_eval)\n",
    "small_data1['keywords'] = small_data1['keywords'].apply(literal_eval)\n",
    "small_data1['cast_size'] = small_data1['cast'].apply(lambda x: len(x))\n",
    "small_data1['crew_size'] = small_data1['crew'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0e19fe24-e206-4743-a96c-fb828707c74d",
    "_uuid": "4207baed79a12ab3314fc816076bbff032d3e186"
   },
   "outputs": [],
   "source": [
    "def get_director(x):\n",
    "    for i in x:\n",
    "        if i['job'] == 'Director':\n",
    "            return i['name']\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d4468b32-a67e-4e31-bd56-1f4467884d1d",
    "_uuid": "64c84be00eb7eb7c0b9c4d9a1605e247c11ce2c6"
   },
   "outputs": [],
   "source": [
    "small_data1['director'] = small_data1['crew'].apply(get_director)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data1['cast'] = small_data1['cast'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "small_data1['cast'] = small_data1['cast'].apply(lambda x: x[:3] if len(x) >=3 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data1['keywords'] = small_data1['keywords'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9f2cbd6e-3729-4316-bb4a-1bcd092f19ff",
    "_uuid": "ac9eb7bb4b74983b9c649013b7cdc6ebbb78af23"
   },
   "source": [
    "We will be creating a metadata dump(combination) for every movie which consists of **genres, director, main actors and keywords.** I then use a **Count Vectorizer** to create our count matrix as we did in the Description Recommender. The remaining steps are similar to what we did earlier: we calculate the cosine similarities and return movies that are most similar.\n",
    "\n",
    "1. **Strip Spaces and Convert to Lowercase** from all  features. This way, engine will not confuse between **Sam Wilson** and **Sam Jones.** \n",
    "2. We will Mention Director 2 times to give it more weight relative to the entire cast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6c5ffd70-ef6b-4fd0-be3d-b3c6a0d72df0",
    "_uuid": "01d86674d50b903fedc79750c4031ca88a739449"
   },
   "outputs": [],
   "source": [
    "small_data1['cast'] = small_data1['cast'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5c1377ba-aad0-4a3f-8bcb-063c9c93f087",
    "_uuid": "7e16f8b131ff73d33463fd070774a24a5ce474df"
   },
   "outputs": [],
   "source": [
    "small_data1['director'] = small_data1['director'].astype('str').apply(lambda x: str.lower(x.replace(\" \", \"\")))\n",
    "small_data1['director'] = small_data1['director'].apply(lambda x: [x,x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5ea1aabb-a885-4dfe-a85e-0e31fd76558f",
    "_uuid": "feac137ab3987ade6ae3b041c6cbec3bf4364e66"
   },
   "source": [
    "#### Keywords\n",
    "\n",
    "We will do a small amount of pre-processing of our keywords before putting them to any use. As a first step, we will calculate the frequenct counts of every keyword that appears in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3dc8f545-4666-4cc0-8473-2870a69e7ff0",
    "_uuid": "5740d11531f7305f4edf13b0270dc014382a2b5c"
   },
   "outputs": [],
   "source": [
    "s = small_data1.apply(lambda x: pd.Series(x['keywords']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'keyword'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "21e684ab-f6d3-4014-a05a-c28f995b4972",
    "_uuid": "1374a54bff3f7f0fdc872bfebff9f81d1dfcea69"
   },
   "outputs": [],
   "source": [
    "s = s.value_counts()\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4277aa18-dc91-4836-9853-2c94624cc70d",
    "_uuid": "0ac999648a3085a98948ccf9ada187a9bb08eba3"
   },
   "source": [
    "Keywords occur in frequencies ranging from 1 to 2170. We do not have any use for keywords that occur only once. Therefore, these can be safely removed. \n",
    "\n",
    "Finally, we will convert every word to its stem so that words such as *Dogs* and *Dog* are considered the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8cabd79b-dfab-46d8-922d-e204173d8103",
    "_uuid": "bf05fb571b1ee60335af20acb9cf5d7fee6254e8"
   },
   "outputs": [],
   "source": [
    "s = s[s >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2d10427d-9339-46fa-b699-060b27d6d25f",
    "_uuid": "1d2a07e4de352df9d3e2230d36e691d166a1675c"
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "stemmer.stem('dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5379c8d7-42a5-471a-84f8-bbd6cadf2e5c",
    "_uuid": "3bad77061d810e52b0d9fecfd26873c101167d00"
   },
   "outputs": [],
   "source": [
    "def filter_keywords(x):\n",
    "    words = []\n",
    "    for i in x:\n",
    "        if i in s:\n",
    "            words.append(i)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "959063e5-841d-408a-a10e-1f1437756b7c",
    "_uuid": "2a939eb8846871c606da0f654a1a9a978270e99f"
   },
   "outputs": [],
   "source": [
    "small_data1['keywords'] = small_data1['keywords'].apply(filter_keywords)\n",
    "small_data1['keywords'] = small_data1['keywords'].apply(lambda x: [stemmer.stem(i) for i in x])\n",
    "small_data1['keywords'] = small_data1['keywords'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "95c45262-2715-47b7-af65-1eb396c37d33",
    "_uuid": "6ff4da392e31cf628f91dd244cc4e76d63c40601"
   },
   "outputs": [],
   "source": [
    "small_data1['combination'] = small_data1['keywords'] + small_data1['cast'] + small_data1['director'] + small_data1['genres']\n",
    "small_data1['combination'] = small_data1['combination'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tmdbv3api import TMDb\n",
    "import json\n",
    "import requests\n",
    "tmdb = TMDb()\n",
    "tmdb.api_key = '68b8a37c9ca19b233cc057643bfbb9eb'\n",
    "from tmdbv3api import Movie\n",
    "tmdb_movie = Movie()\n",
    "def get_poster(x):\n",
    "    response = requests.get('https://api.themoviedb.org/3/movie/{}?api_key={}'.format(x,tmdb.api_key))\n",
    "    if response.status_code==200:\n",
    "        data_json = response.json()\n",
    "        if data_json['poster_path']:\n",
    "            poster_str = 'https://image.tmdb.org/t/p/w500'+data_json['poster_path']\n",
    "            return poster_str\n",
    "        else:\n",
    "            return 'static/default.jpg'\n",
    "    return 'static/default.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking only useful columns into consideration.\n",
    "small_data1.columns\n",
    "small_data1=small_data1[['id','original_title','release_date','title','vote_average','combination']]\n",
    "small_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7f9aa1bc-351b-47a1-b909-0d87efe93adc",
    "_uuid": "c758030ce02bb4beed606e41a3e0a51b659768f0"
   },
   "outputs": [],
   "source": [
    "count = CountVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "count_matrix = count.fit_transform(small_data1['combination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c462b8af-1eb8-499e-8e50-839811aebe9d",
    "_uuid": "defccf8a2c851672447b4f53ff1a8efddafccb33"
   },
   "outputs": [],
   "source": [
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d7ee34aa-da42-46bb-93e5-51e893286353",
    "_uuid": "ffa7edd804b3ea3065c6d428fbb613ae7cd203e3"
   },
   "outputs": [],
   "source": [
    "small_data1 = small_data1.reset_index()\n",
    "titles = small_data1['title']\n",
    "indices = pd.Series(small_data1.index, index=small_data1['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will be apply get_poster function to small chunks of our small_data1 dataset this will help us to remove the Connection Reset error if we used get_poster function on whole dataset.**\n",
    "\n",
    "Now why to apply get_poster function to whole dataset we can also apply it to recommended movies also?\n",
    "We did this to save time to get recommendations of a movie.,if we applied get_poster only for recommended movies it would take up lot of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data1['poster']=np.nan\n",
    "for i in range(2000):\n",
    "    small_data1['poster'][i]=get_poster(small_data1['id'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2000,4000):\n",
    "    small_data1['poster'][i]=get_poster(small_data1['id'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4000,7000):\n",
    "    small_data1['poster'][i]=get_poster(small_data1['id'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7000,9219):\n",
    "    small_data1['poster'][i]=get_poster(small_data1['id'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations1(title):\n",
    "    idx = indices[title]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    try:\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    except:\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1][1], reverse=True)  \n",
    "    sim_scores = sim_scores[1:11]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    tit = small_data1['title'].iloc[movie_indices]\n",
    "    dat = small_data1['release_date'].iloc[movie_indices]\n",
    "    rating = small_data1['vote_average'].iloc[movie_indices]\n",
    "    movieid=small_data1['id'].iloc[movie_indices]\n",
    "    org_title=small_data1['original_title'].iloc[movie_indices]\n",
    "    poster=small_data1['poster'].iloc[movie_indices]\n",
    "    \n",
    "    \n",
    "    return_df = pd.DataFrame(columns=['Title','Year'])\n",
    "    return_df['Title'] = tit\n",
    "    return_df['Year'] = dat\n",
    "    return_df['Ratings'] = rating\n",
    "    return_df['ID']=movieid\n",
    "    return_df['org_title']=org_title\n",
    "    return_df['poster'] =poster\n",
    "    sorted_df = return_df.sort_values(by=['Ratings'], ascending=False)\n",
    "    return sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations1(\"The Dark Knight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pickle module implements binary protocols for serializing and de-serializing a Python object structure.\n",
    "import pickle\n",
    "filename = 'movie_list.pkl'\n",
    "pickle.dump(small_data1, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  We find this recommender system quite good and will be using to to recommend movies on our web application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
